fundamental concepts
* agent
* environment
* rewards

agent interacts with environment.
agent receives rewards for peforming a correct behavior

environment
* what changes when the agent acts
** in the example, environment are the boxes and the rewards

State
* set of all possible states -> "state space"

Agent
* software
* memory of states, actions, rewards
* does not need to be on the hardware
* uses algorithm to inmprove performance
* all possible actions -> "action space"
** Q Learning wants discrete actions

* First Exercise "Frozen Lake"

=====
Markov Chains
actions affect all future rewards
Markov Decison Process
-- each state is based solely on the previous state & action
MPD
MPD underlies the theory of reinforcement learning

p(s',r| a,s) != 1
this defines the dynamics

For continuous tasks, use a decay on the rewards to keep the sum of all rewards is bounded.
use gamma to power step index. gamma^k
The Policy : f: state -> action
